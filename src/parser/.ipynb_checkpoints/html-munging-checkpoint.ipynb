{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='word2html ./Primat_s.docx', returncode=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(\"word2html ./Primat_s.docx\", shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "output = pypandoc.convert_file('Primat_s.docx', to='html', outputfile=\"Primat_s.html\", extra_args=['-s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "надотряд\\b\tотряд\\b\tподотряд\\b\tгипотряд\\b\tинфраотряд\\b\tпарвотряд\\b\tнадсем\\b\\.\tсем\\b\\.\tподсем\\b\\.\tperiod\tdebug\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from lxml import etree\n",
    "import lxml.html\n",
    "import pprint\n",
    "import re\n",
    "import os\n",
    "import cssselect\n",
    "from IPython.display import display, HTML\n",
    "# вручную надо удалить всё после «Географические синонимы»\n",
    "# придумать, как делать дрилл-даун до исходных данных\n",
    "# исключать из рассмотрения Insertae sedis\n",
    "from parglare import Parser, Grammar\n",
    "\n",
    "g = Grammar.from_file(\"grammar.pg\", ignore_case=True)\n",
    "actions = {\n",
    "    \"Tokens\":[lambda _, nodes: nodes[0] if nodes[0] else nodes[1]], # предпочитаем первый\n",
    "    \"Token\": [lambda _, nodes: nodes[1],\n",
    "              lambda _, nodes: nodes[0],\n",
    "              lambda _, value: [],\n",
    "              lambda _, value: []],\n",
    "    \"Layer\": [lambda _, value: [145.0, 66.0],  #Мел\n",
    "              lambda _, value: [ 66.0,  56.0], #Палеоцен\n",
    "              lambda _, value: [ 56.0,  33.9], #Эоцен\n",
    "              lambda _, value: [ 33.9,  23.03],\n",
    "              lambda _, value: [ 23.03,  5.333],\n",
    "              lambda _, value: [ 5.333,  1.806],\n",
    "              lambda _, value: [ 1.806,  0.0117],\n",
    "              lambda _, value: [ 0.0117, 0.0]],\n",
    "    \"LayerPrefix\": [lambda _, value: [],\n",
    "              lambda _, value: [],\n",
    "              lambda _, value: []]\n",
    "}\n",
    "parser = Parser(g, debug=False, debug_trace=True, actions=actions)\n",
    "\n",
    "\n",
    "taxons = [\n",
    "    \"надотряд\\\\b\",\n",
    "    \"отряд\\\\b\",\n",
    "    \"подотряд\\\\b\",\n",
    "    \"гипотряд\\\\b\",\n",
    "    \"инфраотряд\\\\b\",\n",
    "    \"парвотряд\\\\b\",\n",
    "    \"надсем\\\\b\\\\.\",\n",
    "    \"сем\\\\b\\\\.\",\n",
    "    \"подсем\\\\b\\\\.\",\n",
    "#    r\"триба\\b\",\n",
    "]\n",
    "\n",
    "taxonBreadcrumbs = [\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
    "outCSV = \"\\t\".join(taxons + [\"род\", \"period\", \"debug\"])\n",
    "print(outCSV)\n",
    "\n",
    "tree = lxml.html.parse(\"Primat_s.html\").getroot()\n",
    "\n",
    "for e in tree.cssselect(\"span, ul, ol, li, a, font\"): # TODO новый ХТМЛ формат может и не надо так чистить\n",
    "    e.drop_tag()\n",
    "\n",
    "# информация для дебага. Добавляю ссылки, по которым можно будет скроллить документ. Эти номера также попадут в таблицу с данными.\n",
    "for index, e in enumerate(tree.cssselect(\"p, h1, h2, h3, h4, h5, h6, table tr td\")):\n",
    "    anchorStr = \"debug\"+str(index)\n",
    "    anchorElement = etree.Element(\"a\", name=\"debug\"+str(index))\n",
    "    anchorElement.set(\"class\", \"debug\")\n",
    "    anchorElement.tail = e.text\n",
    "    e.text = None\n",
    "    e.insert(0, anchorElement)# = anchorStr + e.text if e.text else anchorStr\n",
    "\n",
    "#tree.get_element_by_id(\"Table of Contents1\").drop_tree() # можно забить, потому что виды всё равно печататься не будут.\n",
    "\n",
    "for e in tree.cssselect(\"p, h1, h2, h3, h4, h5, h6, table tr\"):\n",
    "    #line = re.sub(r\"\\t\", \" \", line)\n",
    "    if e.tag == \"tr\" and len(e)==3: # trying to grab the period\n",
    "        # считываем название рода. Берём первое слово со знаками\n",
    "        genusStr = e[0].text_content()\n",
    "        genusStr = re.sub(r\"\\n|\\t\", r\" \", genusStr)\n",
    "        if re.match(r\"^(\\S+).*\", genusStr, flags=re.DOTALL):\n",
    "            genusStr = re.sub(r\"^(\\S+\\s+\\S*).*\", r\"\\1\", genusStr) #re.DOTALL чтобы обрезать многострочный текст до конца\n",
    "            if genusStr:\n",
    "                # считываем и парсим период\n",
    "                periodStr = e[1].text_content()\n",
    "                periodStr = re.sub(r\"\\n|\\t\", \" \", periodStr)\n",
    "                periodStr = re.sub(r\"\\(.*\\)\", r\"\", periodStr)\n",
    "                periodStr = re.sub(r\"(\\d),(\\d)\", r\"\\1.\\2\", periodStr) # changing digit separator: 0,1 to 0.1\n",
    "                period = parser.parse(periodStr)\n",
    "                #print(\"genus\", genusStr)\n",
    "                #print(\"period\", period)\n",
    "                if period: # если период распарсился TODO не только в этом случае выводить\n",
    "                    debugStr = e[0].get(\"name\")\n",
    "                    outLine = \"\\t\".join(taxonBreadcrumbs+[str(genusStr), str(period), str(debugStr)])\n",
    "                    outCSV = outCSV + os.linesep + outLine\n",
    "                    pass\n",
    "    else: # if it's p, h1 and so on\n",
    "        paragraphStr = e.text_content()\n",
    "        paragraphStr = re.sub(r\"\\n|\\t\", r\" \", paragraphStr)\n",
    "        for index, t in enumerate(taxons):\n",
    "            #match = re.sub(r\"^\\s*(\"+t+\".*)\", \"* \"*index+r\"* \\1\", line, flags=re.IGNORECASE)\n",
    "            #print(paragraphStr)\n",
    "            if re.search(r\"^\\s*(\"+t+\".*)\", paragraphStr, flags=re.IGNORECASE):\n",
    "                # Когда спускаемся по цепочке таксонов, запоминаем все, что выше.\n",
    "                taxon = re.sub(r\"^\\s*\"+t+r\"\\s*\\b(\\w+)\\b.*\", r\"\\1\", paragraphStr, flags=re.IGNORECASE)\n",
    "                #print(taxon)\n",
    "                taxonBreadcrumbs[index] = taxon\n",
    "                # А если надо подняться наверх, Пр. на уровень семейства, меняем название семейства, всё, что ниже — стираем.\n",
    "                # Если проваливаемся сразу на несколько уровней, то они остаются пустыми.\n",
    "                taxonBreadcrumbs = taxonBreadcrumbs[:index+1]\n",
    "                taxonBreadcrumbs.extend([\"\"]*(len(taxons)-index-1))\n",
    "                #print(taxonBreadcrumbs)\n",
    "                break;\n",
    "\n",
    "\n",
    "#for e in tree.cssselect(\"table>tr\"):\n",
    "#    if(len(e)==3):\n",
    "#        pass\n",
    "        #e[0].text = \"111\"\n",
    "\n",
    "#display(HTML(str(lxml.html.tostring(tree)))) работает, но выводить в ХТМЛ кучу \\n\\t\n",
    "        \n",
    "out = open('out.tsv', 'w')\n",
    "#result = lxml.html.tostring(tree, pretty_print=True, method=\"html\")\n",
    "out.write(outCSV)\n",
    "out.close()\n",
    "\n",
    "out = open('Primat_s_debug.html', 'w')\n",
    "result = lxml.html.tostring(tree, pretty_print=True, method=\"html\", encoding='unicode')\n",
    "#print(result[:30000])\n",
    "out.write(result)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from parglare import Parser, Grammar\n",
    "\n",
    "grammar = r\"\"\"\n",
    "Text: Tokens | EMPTY;\n",
    "Tokens: Token Tokens?;\n",
    "Token: LayerPrefix Layer {3}\n",
    "     | Layer {2}\n",
    "     | Skip {1} \n",
    "     | LayerPrefix {1};\n",
    "Layer: Mel_fixme\n",
    "     | Paleocene\n",
    "     | Eocene \n",
    "     | Oligocene \n",
    "     | Miocene \n",
    "     | Pliocene \n",
    "     | Pleistocene \n",
    "     | Holocene\n",
    "     ;\n",
    "LayerPrefix: Upper \n",
    "     | Middle \n",
    "     | Lower;\n",
    "\n",
    "terminals\n",
    "Mel_fixme: \"Мел\";\n",
    "Paleocene: \"Палеоцен\";\n",
    "Eocene: \"Эоцен\";\n",
    "Oligocene: \"Олигоцен\";\n",
    "Miocene: \"Миоцен\";\n",
    "Pliocene: \"Плиоцен\";\n",
    "Pleistocene: \"Плейстоцен\";\n",
    "Holocene: \"Голоцен\";\n",
    "\n",
    "Upper: \"в.\";\n",
    "Middle: \"ср.\";\n",
    "Lower: \"н.\";\n",
    "\n",
    "Skip: /./;\n",
    "\"\"\"\n",
    "\n",
    "actions = {\n",
    "    \"Tokens\":[lambda _, nodes: nodes[0] if nodes[0] else nodes[1]], # предпочитаем первый\n",
    "    \"Token\": [lambda _, nodes: nodes[1],\n",
    "              lambda _, nodes: nodes[0],\n",
    "              lambda _, value: [],\n",
    "              lambda _, value: []],\n",
    "    \"Layer\": [lambda _, value: [145.0, 66.0],  #Мел\n",
    "              lambda _, value: [ 66.0,  56.0], #Палеоцен\n",
    "              lambda _, value: [ 56.0,  33.9], #Эоцен\n",
    "              lambda _, value: [ 33.9,  23.03],\n",
    "              lambda _, value: [ 23.03,  5.333],\n",
    "              lambda _, value: [ 5.333,  1.806],\n",
    "              lambda _, value: [ 1.806,  0.0117],\n",
    "              lambda _, value: [ 0.0117, 0.0]],\n",
    "    \"LayerPrefix\": [lambda _, value: [],\n",
    "              lambda _, value: [],\n",
    "              lambda _, value: []]\n",
    "}\n",
    "\n",
    "g = Grammar.from_string(grammar, ignore_case=True)\n",
    "#parser = Parser(g, debug=False, debug_trace=True)\n",
    "parser = Parser(g, debug=False, debug_trace=True, actions=actions)\n",
    "\n",
    "#result = parser.parse(\"     - в.палеоцен-н.-ср.-???в.эоцен\")\n",
    "result = parser.parse(\"\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
